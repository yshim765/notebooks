# A SURVEY ON CONTRASTIVE SELF-SUPERVISED LEARNING

自己教師あり学習のサーベイ。

* ABSTRACT
    * 大規模なデータセットのアノテーションにはコストがかかるため、それを回避できる自己教師付き学習が人気を集めている。
    * 自己教師付き学習は、自分で定義した疑似ラベルを教師データとして採用し、学習した表現をいくつかの下流のタスクに使用する手法。
    * 特に最近のcontrastive learningは、コンピュータビジョンや自然言語処理（NLP）などの分野における自己教師付き学習法の主要な要素となっている。
    * contrastive learningは、データサンプルとオーグメンテーションしたサンプルは互いに近づけ、異なるサンプルは離すように潜在空間を学習させる。
    * この論文では、contrastive learningの設定で一般的に使用されるプレテクストタスクについて説明し、続いてこれまでに提案されてきた様々なアーキテクチャを紹介する。
    * 次に、画像分類、物体検出、行動認識などの複数の下流タスクについて、異なる手法の性能比較を行う。
* Introduction
    * コンピュータビジョン（CV）や自然言語処理（NLP）など、様々なタスクで深層学習は必須の技術となっている。
    * しかし、ラベル付きデータから特徴量を学習する教師付きアプローチは、何百万ものデータサンプルに手動でアノテーションを施すという多大な労力を必要とするため、ほぼ性能の限界に達している。
    * 従来の教師付き学習アプローチは、アノテーションされた学習データの量に大きく依存していた。
    * しかし、膨大な量のデータがあるにもかかわらず、アノテーションがないという問題があった。
    * そこで、高価なアノテーションを必要とせず、データ自身が教師データを提供する自己教師付き手法が深層学習の発展に重要な役割を果たしている。
    * 自己教師付き学習の手法として、GANのような生成モデルのように、自分自身のデータを再現するように学習させる手法がある。
    * しかし、GANベースの手法は、モデルが収束しなかったり識別機が強くなりすぎて生成モデルが学習できなくなったりする問題がある。
    * 生成モデルベースの手法とは異なり、contrastive learningは類似したサンプルをより近くに、それ以外のサンプルを遠くにグループ化することを目的とした識別的なアプローチである。
    * それを実現するためには、埋め込まれた潜在空間のベクトル同士の距離を図る指標が使われる。
    * contrastive learningでは、あるデータAとAをオーグメンテーションしたデータを近くに、バッチのA以外のデータを遠くに配置することで学習される。
        * そのため、手法によってはcontrastive learningでは完全に教師なしでも実施することが可能。
    * 最近の contrastive learning である SwAV、MoCo、SimCLR は教師あり学習に匹敵する性能を出している。
* Pretext Tasks
    * Pretext Taskは、疑似ラベル（pseudo labels）を用いてデータの表現を学習する自己教師付きタスクである。
    * これらの疑似ラベルは、データに含まれる性質に基づいて自動的に生成されます。
        * 色変換、幾何学的変換など。
    * Pretext Taskで学習されたモデルは、コンピュータビジョンにおける分類、セグメンテーション、検出などの下流のタスクに使用することができる。
    * さらに、理論上はこれらのPretext Taskは、画像に限らずビデオ、音声、信号など、あらゆる種類のデータに適用できる。
        * そのための必要な条件としては、適切なデータオーグメンテーションができることのような気がする。
        * 適切なデータオーグメンテーションができる -> データのラベルを変えずに類似データを生成できる手法があるということ
    * contrastive learningのプレテキストタスクでは、元画像をアンカーとし、そのオーグメンテーション（変換）版が正のサンプル、バッチまたはトレーニングデータ内の残りの画像が負のサンプルとして学習させる。
    * よく使われるのは色変換、幾何学的変換、コンテキストベースのタスク、クロスモーダルベースのタスクの4つ。
        * 色変換
            * 画像の色変換、ぼかし、色の歪み、グレースケールへの変換など。
        * 幾何学的変換
            * スケーリング、ランダムクロッピング、反転（水平、垂直）など。
        * コンテクスト・ベース
            * ジグソーパズルのように画像を分割したものの位置を入れ替えたものを正のサンプルとする手法。
            * フレームオーダーベースの手法。
                * 時系列データの場合、自身と近くのサンプルは似ていることを利用できる。
                    * 同じ動画から2つの短いシーンを抜き出して正のサンプルにする、時間的にシャッフルした動画を正のサンプルとするなど。
                    * 時間的に近いデータ、もしくは同じ動画内のデータは近いという考え方は、状態空間モデルにおける潜在空間の遷移が近いと仮定している状態と似ている気がする。
                    * 時系列データに対するcontrastive learningの適用は、深層学習を使って状態空間モデル的なものを作ろうとしているのかもしれない。
        * クロスモーダルベース
            * 同じ場所を同じ時間に複数の視点から撮影した画像、動画を使用する。
            * 別の時間に撮影した画像とは離れている方が好ましい。
    * 適切なPretext Taskの選定
        * Pretext Taskの選択は、解決する問題のタイプに依存する。
        * これまでの研究により、contrastive learningでモデルがうまく機能するためには、適切な種類のPretext Taskを使用することが重要であることが明らかになっている。
        * Pretext Taskの主な目的は、他のデータポイントに対する識別性を保ちつつ、変換に対してモデルが不変であることを強制すること。
        * しかし、このような拡張によってもたらされるバイアスは諸刃の剣となる可能性がある。
        * というのも、それぞれの拡張は、ある場合には有益であり、ある場合には有害である変換に対する不変性を促すため。
        * 例えば、回転を適用すると、視野に依存しない空中での画像認識には役立つかもしれないが、ディスプレイ用途の写真でどちらが上かを検出するといった下流のタスクを解決しようとすると、性能が大幅に低下する可能性がある。
        * 同様に、色付けに基づくプレテクストタスクは、図 9 で表されるような細かい分類ではうまくいかないかもしれない。
        * 回転を除き、スケーリングやアスペクト比の変更などの他の変換は、容易に検出可能な視覚的アーティファクトを生成するため、Pretext Taskには適していない可能性があると指摘する論文もある。
        * また、その論文では図 10 に示すように、ターゲットデータセットの画像が、DTD データセットのようにカラーテクスチャで構成されている場合、回転はうまく機能しないことも明らかにしている。
    * NLP におけるPretext Task
        * NLPでのPretext Taskとは、教師ありのアプローチを教師なしの問題に適用して、モデルを事前学習できるようなラベルを生成することを指す。
        * NLPの方が昔からcontrastive learning的な手法をいろいろ試している感じがする。
        * Center and Neighbor Word Prediction
            * Word2Vecもcontrastive learningの一種。
            * アンカーとなる元データは欠損した単語、正例のデータは周囲の単語、負例のデータはランダムにサンプルされてきた単語、という認識（間違ってるかも）。
            * "center word prediction"では、モデルへの入力は固定の窓サイズを持つ単語のシーケンスで、シーケンスの中心から 1 つの単語が欠けている。
            * モデルのタスクは、単語列の中で欠けている単語を予測すること。
            * "neighbor word prediction"の入力は 1 つの単語で、モデルはその隣接する単語を予測する。
        * Next and Neighbor Sentence Prediction
            * Next Sentence Prediction では 2 つの入力文が連続した文になるかどうかをモデルが予測する。
            * この場合の正のサンプルは元の文に続くサンプルであり、負のサンプルはランダムな文書からの文。
            * 文が与えられたときに、その前の文と次の文を予測するのが「Neighbor Sentence Prediction」。
            * これはNeighbor Word Predictionに似ているが、単語の代わりに文に適用される。
        * Auto-regressive Language Modeling
            * 前の単語が与えられたときに次の単語を予測したり、その逆を行ったりする。
            * この手法は、GPT[32]やその最近のバージョンなど、いくつかの N-gram モデルやニューラルネットワークで使用されている。
        * Sentence Permutation
            * BART では、コーパスから連続したテキストを取り出し、複数の文に分割するPretext Taskを使用している。
            * 文章の位置はランダムに入れ替えられ、モデルのタスクは文章の元の順序を予測すること。
* Architectures
    * contrastive learningでは良質な表現を生成するために、負のサンプルの数が重要となる。
    * これは、辞書を探すタスクと見なすことができ、辞書はトレーニングセット全体の場合もあれば、データセットの一部のサブセットの場合もある。
    * この負のサンプルを探す手法をEnd-to-End、Memory Bank、Momentum Encoder、Clusteringの4種類に分類した。
    * End-to-End
        * アンカーになる元データの埋め込み表現を学習させるクエリエンコーダ（Q）と、正例、負例の埋め込み表現を学習させるキーエンコーダ（K）の2つを作り、両方ともバックプロパゲーションで更新される。
        * contrastive lossを使って、正のサンプルは元のサンプルに近づけ，負のサンプルは遠ざけるように学習される。
        * 類似性指標としてコサイン類似度が使われる。
        * 図 12 に示すように、バッチサイズが大きく、エポック数が多いほど性能が向上することが確認されている。
        * 強力な自己回帰モデルとコントラスト損失を用いて、潜在空間で未来を予測することにより、高次元時系列データの特徴表現を学習することもできるらしい。
        * End-to-End な手法の難点としては、バッチサイズは GPU のメモリサイズによって制限されるため、GPUがボトルネックになる点がある。
        * ミニバッチ最適化の問題も出てくるらしい。
    * Memory Bank
        * バッチサイズが大きくなると最適化の問題が出てくるので、メモリバンクと呼ばれる別の辞書を保持することで解決する手法。
        * 最適化の問題とは？
            * キーエンコーダ の gradient をバックプロパゲーションする時にコストが大きくてGPU依存になるとかかな。
        * 過去数エポック分のサンプルの埋め込みの指数的移動平均を辞書として保存して使うらしい。
        * 表現が数回のパスですぐに古くなってしまうため、メモリバンクの表現を更新するのに計算量がかかることが難点。
    * Momentum Encoder
        * 上記のメモリーバンクの難点を改善するため、メモリバンクの代わりに「モーメンタムエンコーダ」を使用する手法がある。
        * keyのモーメンタムエンコーダはバックプロパゲーションされない。
        * 代わりに、keyのパラメータ θ_k は、queryのパラメータ θ_q とmomentum coefficient の m を使って以下のように更新される。
        * θ_k ← m \* θ_k + (1 − m) \* θ_q
        * これにより、keyのエンコーダの最適化の問題がなくなるらしい。
    * Clustering
        * End-to-Endなアプローチに、似ている埋め込み表現を持つサンプル群がクラスタを作るような処理を入れたもの。
        * クラスタ数のハイパーパラメータをどうやって決めるのかは謎。
            * 想定されるラベル数とかを基準にするのだろうか。
            * weakly supervisedな雰囲気を感じる。
* Encoders
    * エンコーダーは，入力されたサンプルを潜在空間にマッピングする役割を担う。
    * contrastive learningではResNet（特に、ResNet-50）のアーキテクチャがよく使われる。
    * 最後の層に128次元のMLPを噛ませてcontrastive learningをするらしい。
    * エンコーダの後段から抽出した特徴量の方がデータをマッピングするのに適しているらしい。
* Training
    * エンコーダの学習では、前述のPretext Taskを使う。
    * 学習の際は埋め込み表現の近さを測定する類似性メトリックが必要となる。
    * 一例としてコサイン類似度がある。
    * 学習のロスはNoise Contrastive Estimation (NCE)と呼ばれるものが使われる。
        * この関数は、元々は実測データと人工的に生成されたノイズを見分けることを目的として作られたものだったらしい。
    * 負のサンプル数が多い場合はInfoNCEと呼ばれるものが使われる。
        * L2正規化してるような感じらしい。
        * いろんなデータに対して全体的に類似度を0にする方向に学習する感じ？
    * 最適化アルゴリズムはいろいろ。
        * SDGとかAdamとか。
        * LARS(Layer-wise Adaptive Rate Scaling)とかあるらしい（なにそれ？）
        * とりあえずAdamでいいのでは、という気もするけどなんでSDGを使うんだろう。
        * 引用してるのがちょっと前の論文だったり？
* Downstream Tasks
    * 画像系の下流タスクは分類、検出、セグメンテーション、未来予測とか。
    * ちゃんと潜在空間が正しく作れているかも重要なのでそういうとこを見たりするらしい。
    * 画像のモデルの場合、Feature Mapsを可視化してもそれなりに物体の場所を見ているっぽい。
    * kNNで近いデータを調べるのも良い。
* Benchmarks
    * 最近の手法なら教師ありと比べても遜色ない性能が出ている。
    * ImageNetで学習したモデルをPlacesに転用しても使えるなど、ある程度のドメイン変化でも対応できるらしい。
* Contrastive Learning in NLP
    * NLPでも適用例がある。
* Discussions and Future Directions
    * contrastive learningにもまだいくつか課題は存在する。
    * 理論的基盤が弱い。
    * 下流タスクに対してどのようなデータ補強とPretext Taskを選べばよいのかイマイチ良い基準がない。
        * これは、適用したい下流タスクに対してどのような潜在空間が適切なのかわかっていないことが原因では。
        * 理論的な解析が進めば解決する話なんだろうか。
    * 適切な負例を選ぶ方法が重要だが、決定的な方法がない。
        * 犬の画像に対して負例として飛行機の画像を持ってくると簡単すぎてモデルが学習できないので、それなりに犬に近いが犬ではない画像を適切に選んでくる方法が必要だということ。
    * 自己教師付き学習ではデータ自体が教師となるので、バイアスの少ないデータセットを用意しないと性能が十分に発揮できない。
        * 自己教師付きに限らないけど、まあそれはそう。
